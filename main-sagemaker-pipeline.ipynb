{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an Amazon SageMaker Pipeline to Transform Raw Texts to A Knowledge Graph\n",
    "\n",
    "This repo provides an [Amazon SageMaker](https://aws.amazon.com/sagemaker/) Pipeline to train and deploy an ML model to transform raw text files to a knowledge graph which will be stored in an [Amazon Neptune](https://aws.amazon.com/neptune/) graph database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code architecture of this repo is demonstrated as below:\n",
    "\n",
    "```\n",
    "|-- pipelines\n",
    "|   |-- kg\n",
    "|   |   |-- __init__.py\n",
    "|   |   |-- alert.py\n",
    "|   |   |-- bulkload.py\n",
    "|   |   |-- createdb.py\n",
    "|   |   |-- dataset.py\n",
    "|   |   |-- evaluate.py\n",
    "|   |   |-- inference.py\n",
    "|   |   |-- model.py\n",
    "|   |   |-- pipeline.py\n",
    "|   |   |-- preprocess.py\n",
    "|   |   |-- train.py\n",
    "|   |   |-- utils.py\n",
    "|   |   |-- requirements.txt\n",
    "|-- main-sagemaker-pipeline.ipynb\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment preperation\n",
    "Firstly let's upgrade SageMaker and make sure the version number >= 2.59.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade pip\n",
    "! python3 -m pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your `default_bucket` or use `sagemaker.session.Session().default_bucket()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_bucket = sagemaker.session.Session().default_bucket()\n",
    "default_bucket = 'sm-pipeline-kg'\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sess = boto3.session.Session()\n",
    "s3_client = sess.client('s3')\n",
    "\n",
    "existing_buckets = s3_client.list_buckets()['Buckets']\n",
    "existing_flag = False\n",
    "for s3_bucket in existing_buckets:\n",
    "    if default_bucket == s3_bucket['Name']:\n",
    "        existing_flag = True\n",
    "        print('Bucket existed')\n",
    "    \n",
    "if not existing_flag:\n",
    "    print(f'\\'{default_bucket}\\' does not exist! Creating bucket \\'{default_bucket}\\'...' )\n",
    "    try:\n",
    "        response = s3_client.create_bucket(Bucket=default_bucket,\n",
    "          CreateBucketConfiguration={\n",
    "              'LocationConstraint': region\n",
    "          })\n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "            print(\"Bucket created successfully!\")\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data for the pipeline.\n",
    "\n",
    "Download the Language Understanding and Generation Evaluation Benchmarks (LUGE) dataset from this link: <a>http://dataset-bj.cdn.bcebos.com/qianyan/DuIE_2_0.zip</a>. Use of the LUGE dataset is subject to the terms contained in the License.pdf file included in the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = input(\"Download the Language Understanding and Generation Evaluation Benchmarks (LUGE) dataset from this link: \" + \n",
    "                 \"http://dataset-bj.cdn.bcebos.com/qianyan/DuIE_2_0.zip. \" + \"Use of the LUGE dataset is subject to the terms contained in the License.pdf file included in the zip file. \" + \n",
    "                 \"Input “yes” to accept the terms of license.\")\n",
    "\n",
    "if (decision == 'yes'):\n",
    "    !wget http://dataset-bj.cdn.bcebos.com/qianyan/DuIE_2_0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$default_bucket\"\n",
    "\n",
    "aws s3 cp DuIE_2_0.zip \"s3://$1/ie-baseline/raw/DuIE_2_0.zip\"\n",
    "rm DuIE_2_0.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload test data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ./pipelines/kg/data/psudo_transform_input.json s3://$default_bucket/psudo/psudo.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether data exists at the desired location which will be used in the future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input_data_s3_uri = f\"s3://{default_bucket}/ie-baseline/raw/DuIE_2_0.zip\"\n",
    "!aws s3 ls $raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the pipeline instance\n",
    "\n",
    "Here we get the pipeline instance from your pipeline module so that we can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.kg.pipeline import get_pipeline\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "pipeline = get_pipeline(\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=default_bucket,\n",
    "    model_package_group_name='KGModelPackageGroup',\n",
    "    pipeline_name='KGPipeline',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit our pipeline definition to the workflow service. The role passed in will be used by the workflow service to create all the jobs defined in the steps. `upsert` update or insert parameters, and then create the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the pipeline in [Amazon SageMaker Studio](https://aws.amazon.com/sagemaker/studio/) like below.\n",
    "\n",
    "<div align=\"left\"><img width=500 src=\"./img/KG-pipeline-graph.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the pipeline definition in \"Pretty\" mode and get the detailed information of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "pprint(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start pipeline execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pipeline created above, we defined a group of paramters, and each time you execute the pipeline, you can pass different values to these parameters.\n",
    "\n",
    "<table align='left'>\n",
    "    <caption>SageMaker Pipeline Parameters</caption>\n",
    "    <tr>\n",
    "        <th style=\"text-align:left\">Parameter</th>\n",
    "        <th style=\"text-align:left\">Type</th>\n",
    "        <th style=\"text-align:left\">Description</th>\n",
    "        <th style=\"text-align:left\">Default</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">InputDataset</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">S3 path of input dataset</td>\n",
    "        <td style=\"text-align:left\">s3://{default_bucket}/ie-baseline/raw/DuIE_2_0.zip</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">ProcessingOutputData</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">S3 path of processed data</td>\n",
    "        <td style=\"text-align:left\">s3://{default_bucket}/ie-baseline/processed/</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">ProcessingInstanceType</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Type of instance to perform data processing</td>\n",
    "        <td style=\"text-align:left\">ml.c5.2xlarge</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">ProcessingInstanceCount</td>\n",
    "        <td style=\"text-align:left\">Integer</td>\n",
    "        <td style=\"text-align:left\">Number of instances to perform data processing</td>\n",
    "        <td style=\"text-align:left\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">TrainInstanceType</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Type of instance to perform model training</td>\n",
    "        <td style=\"text-align:left\">ml.g4dn.4xlarge</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">TrainInstanceCount</td>\n",
    "        <td style=\"text-align:left\">Integer</td>\n",
    "        <td style=\"text-align:left\">Number of instances to perform model training</td>\n",
    "        <td style=\"text-align:left\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Epochs</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Number of epochs of model training</td>\n",
    "        <td style=\"text-align:left\">20</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">LearningRate</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Learning rate of model training</td>\n",
    "        <td style=\"text-align:left\">0.001</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">BatchSize</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Batch size of model training</td>\n",
    "        <td style=\"text-align:left\">64</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">AlertTopic</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Topic of Amazon SNS alert email</td>\n",
    "        <td style=\"text-align:left\">KGPipelineAlert</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">EvaluationInstanceCount</td>\n",
    "        <td style=\"text-align:left\">Integer</td>\n",
    "        <td style=\"text-align:left\">Number of instances to perform model evaluation</td>\n",
    "        <td style=\"text-align:left\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">EvaluationInstanceType</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Type of instance to perform model evaluation</td>\n",
    "        <td style=\"text-align:left\">ml.c5.2xlarge</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">TransformModelName</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Name of the Amazon SageMaker model</td>\n",
    "        <td style=\"text-align:left\">transform-model-{time}</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">InferenceInstanceType</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Type of instance to perform model inference</td>\n",
    "        <td style=\"text-align:left\">ml.c5.4xlarge</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">NeptuneClusterIdentifier</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Name of the Amazon Neptune cluster</td>\n",
    "        <td style=\"text-align:left\">kg-neptune</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">IamLoadFromS3RoleName</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Name of the IAM role created for data loading to Neptune database</td>\n",
    "        <td style=\"text-align:left\">NeptuneLoadFromS3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">BulkloadInstanceType</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Type of instance to bulk load data to the Neptune database</td>\n",
    "        <td style=\"text-align:left\">ml.m4.xlarge</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">TransformInstanceType</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Type of instance to perform batch transform</td>\n",
    "        <td style=\"text-align:left\">ml.c5.4xlarge</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">BatchData</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">S3 path of data for batch transform</td>\n",
    "        <td style=\"text-align:left\">s3://{default_bucket}/psudo/psudo.json</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">ModelApprovalStatus</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Status of model approvement</td>\n",
    "        <td style=\"text-align:left\">PendingManualApproval</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">DeployInstanceType</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Type of instance for model deployment</td>\n",
    "        <td style=\"text-align:left\">ml.m4.xlarge</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">AlertEmails</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Email address to receive SNS alert</td>\n",
    "        <td style=\"text-align:left\"> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">AlertPhones</td>\n",
    "        <td style=\"text-align:left\">String</td>\n",
    "        <td style=\"text-align:left\">Phone number to receive SNS message</td>\n",
    "        <td style=\"text-align:left\"> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">MinF1Value</td>\n",
    "        <td style=\"text-align:left\">Float</td>\n",
    "        <td style=\"text-align:left\">Threshold of condition</td>\n",
    "        <td style=\"text-align:left\">0.5</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this execution, we will overwrite several parameters of the pipeline:\n",
    "* InputDataset\n",
    "* ProcessingOutputData\n",
    "* BatchData\n",
    "* NeptuneClusterIdentifier\n",
    "* IamLoadFromS3RoleName\n",
    "* AlertEmails\n",
    "\n",
    "Please pay attention to the `AlertEmails` paramter. Make sure you have access to the email address passed to the `AlertEmails` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        InputDataset=raw_input_data_s3_uri,\n",
    "        ProcessingOutputData=f\"s3://{default_bucket}/ie-baseline/processed/\",\n",
    "        BatchData=f\"s3://{default_bucket}/psudo/psudo.json\",\n",
    "        NeptuneClusterIdentifier='kg-neptune-v1',\n",
    "        IamLoadFromS3RoleName='NeptuneLoadFromS3Role',\n",
    "        AlertEmails='xxx@xxx.com', # Make sure you have access to this email. \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can describe the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the execution by invoking `wait()` on the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the pipeline in [Amazon SageMaker Studio](https://aws.amazon.com/sagemaker/studio/) and observe the execution like below. The execution will take about 1.5 hours.\n",
    "\n",
    "<div align=\"left\"><img width=500 src=\"./img/sm-pipeline-graph.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the exectuion, if the model fails to pass `F1Condtion`, your `AlertEmails` address will receive an email to confirm the subscription to an [Amazon SNS](https://aws.amazon.com/sns/) topic. After clicking Confirm subscription link in the email, you will be directed to a webpage like below:\n",
    "\n",
    "<div align=\"left\"><img width=500 src=\"./img/sns-subscription.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Check outputs of the pipeline exectution\n",
    "\n",
    "After the execution completes, we will have several outputs:\n",
    "* A SagaMaker model (you can find it in the inference page of SageMaker console): <div align=\"left\"><img width=800 src=\"./img/sagemaker-model.png\"></div>\n",
    "<br/>\n",
    "* A Neptune Database (you can find it Amazon Neptune console)<div align=\"left\"><img width=800 src=\"./img/neptune-kg-db.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interact with the graph database\n",
    "\n",
    "There are several ways to interact with a Neptune database. The best way to effectively explore the database is to create and use a Notebook in Neptune console. You can find detailed introductions [here](https://docs.aws.amazon.com/neptune/latest/userguide/graph-notebooks.html).\n",
    "\n",
    "In this notebook, you can perform queries to the Neptune database. First, let's install necessary code packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install gremlinpython\n",
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a helper function to send queries to the Neptune database and get responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gremlin_python import statics\n",
    "from gremlin_python.structure.graph import Graph\n",
    "from gremlin_python.process.graph_traversal import __\n",
    "from gremlin_python.process.strategies import *\n",
    "from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def query_neptune(expr, neptune_endpoint, port):\n",
    "    graph = Graph()\n",
    "    if port == 80 or port == '80': # use unencrypted web socket if port is an http port\n",
    "        neptune_web_socket = f\"ws://{neptune_endpoint}:{port}/gremlin\"\n",
    "    else:\n",
    "        neptune_web_socket = f\"wss://{neptune_endpoint}:{port}/gremlin\"\n",
    "    \n",
    "    remoteConn = DriverRemoteConnection(neptune_web_socket, 'g')\n",
    "    g = graph.traversal().withRemote(remoteConn)\n",
    "    result = eval(expr)\n",
    "    remoteConn.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please provide your `Neptune Endpoint` and `Port` information below. You can find those information in the Neptune console. Detailed instructons can be found [here](https://docs.aws.amazon.com/neptune/latest/userguide/feature-overview-endpoints.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'xxx.xxx.neptune.amazonaws.com'\n",
    "port = 8182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are sevaral languages that can be used to query a Neptune graph. In this repo, we will use [Gremlin](https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin.html) to perform querying. <br />\n",
    "Below is a list of sample queries, and you can write you own queries using Gremlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"g.V().toList()\",\n",
    "    \"g.E().toList()\",\n",
    "    \"g.V().has('影视作品', 'name', '末日迷踪').out('主演').values('name').toList()\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_neptune(queries[2], endpoint, port)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
